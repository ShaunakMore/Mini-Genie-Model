{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e277687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import minigrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd7c11",
   "metadata": {},
   "source": [
    "Create an environment and run the environment with random sampled actions to generate data for the model in the form \n",
    "`(initial_frame, action, next_frame)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee688515",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MiniGrid-Empty-5x5-v0\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa09162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for episodes in range(550):\n",
    "    done =  False\n",
    "    obs, _ = env.reset()\n",
    "    frame = env.render()\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, truncated, info = env.step(action=action)\n",
    "        next_frame = env.render() \n",
    "\n",
    "        dataset.append([frame,action,next_frame])\n",
    "        frame = next_frame\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf238e6",
   "metadata": {},
   "source": [
    "Process the `dataset` array and convert the stored values into an `np` array and transpose to store in the (C, H, W) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca3c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_samples = []\n",
    "for initial_state, action, final_state in dataset:\n",
    "    initial_state = np.array(initial_state,dtype=np.float32)\n",
    "    final_state = np.array(final_state, np.float32)\n",
    "    \n",
    "    initial_state = cv2.resize(initial_state, (64 , 64))\n",
    "    final_state = cv2.resize(final_state, (64,64))\n",
    "    \n",
    "    initial_state /= 255.0\n",
    "    final_state /= 255.0\n",
    "    \n",
    "    processed_samples.append((initial_state,action,final_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace70829",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_frames = np.array([s[0] for s in processed_samples],dtype=np.float32)\n",
    "actions = np.array([s[1] for s in processed_samples],dtype=np.int32)\n",
    "final_frames = np.array([s[2] for s in processed_samples],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a3d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_frames = initial_frames.transpose((0,3,1,2))\n",
    "final_frames = final_frames.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf82e40",
   "metadata": {},
   "source": [
    "Save the `np` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90228f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('images.npy', initial_frames)\n",
    "np.save('actions.npy', actions)\n",
    "np.save('next_frames.npy', final_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
